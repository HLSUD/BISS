### NLE config
# debug: True
batch_size: 8
num_workers: 0
lr: 0.001
weight_decay: 0.001
patience: 2
factor: 0.5
num_epoch: 5
device: torch.device("cuda" if torch.cuda.is_available() else "cpu")

local_rank: 0
pretrained: False # for both image encoder and text encoder
trainable: False # for audio encoder
temperature: 1.0
root_path: "."
output_path: "."
seed: 2023

# for projection head; used for both image and text encoders
num_projection_layers: 1
out_dims: 256
dropout: 0.1
# temperature: 0.003

# TEXT ENCODER CONFIG
text_model: "bert-base-uncased"
text_len: 100
# transformer_embed_dim: 768
# freeze_text_encoder_weights: True
text_cl: "bert"

# AUDIO ENCODER CONFIG
audioenc_name: "whisper"
# out_emb: 2048
#sampling_rate: 44100
#fmin: 50
#fmax: 14000
#n_fft: 1028
#hop_size: 100
#mel_bins: 64
#window_size: 1024
duration: 5
audio_model: "large"
processor_model: "openai/whisper-base.en"
transformer_embed_dim: 1280

# EEG ENCODER CONFIG
hop_size: 100
smooth: True # smooth eeg signals
embed_dim: 1024
channels: 128
timepoints: 512
depth: 24
heads: 16
eeg_pretrain_path: "./checkpoints/eeg_pretrain.pth"
